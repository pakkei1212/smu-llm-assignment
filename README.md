
# ğŸ“Š SMU LLM Assignment â€“ Financial Sentiment Classification

## ğŸ“Œ Project Overview

This project implements financial news sentiment classification using multiple transformer architectures and fine-tuning strategies.

The task is to classify financial headlines into:
- negative
- neutral
- positive

Both Full Fine-Tuning (FFT) and LoRA (Low-Rank Adaptation) are implemented and compared across multiple models.

---

## ğŸ“‚ Repository Structure
```
smu-llm-assignment-main/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ all-data.csv
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ 00_testing.ipynb
â”‚   â”œâ”€â”€ 01_data_loading.ipynb
â”‚   â”œâ”€â”€ 01_data_loading-nvd.ipynb
â”‚   â”œâ”€â”€ 02_training_lora(bert-base-cased).ipynb
â”‚   â”œâ”€â”€ 02_training_lora(bert-base-uncased).ipynb
â”‚   â”œâ”€â”€ 02_training_lora(deberta-v3-base).ipynb
â”‚   â”œâ”€â”€ 02_training_lora(finbert-tone).ipynb
â”‚   â”œâ”€â”€ 02_training_lora(qwen).ipynb
â”‚   â”œâ”€â”€ 02_training_lora-nvd.ipynb
â”‚   â””â”€â”€ 03_evaluation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ BaseTrainer.py
â”‚   â”œâ”€â”€ EncoderTrainer.py
â”‚   â”œâ”€â”€ DecoderTrainer.py
â”‚   â”œâ”€â”€ Seq2SeqTrainer.py
â”‚   â”œâ”€â”€ ClassificationEvalTrainer.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ sbatchTemplatePython.sh
```
---

## ğŸ§  Architecture Design

### BaseTrainer.py
Abstract base class defining:
- Model loading
- Tokenizer setup
- Device resolution
- Training loop integration

### EncoderTrainer.py
Used for encoder-based models such as BERT, DeBERTa, and FinBERT.
Implements AutoModelForSequenceClassification for classification.

### DecoderTrainer.py
Used for causal LLMs (e.g., Qwen).
Handles instruction-style prompt formatting and generation-based classification.

### Seq2SeqTrainer.py
Used for sequence-to-sequence models (e.g., T5-style models).

### ClassificationEvalTrainer.py
Custom trainer extending HuggingFace Trainer:
- Custom loss computation (optional class weights)
- Macro F1 evaluation
- Extended metric logging

---

## ğŸ”§ Fine-Tuning Methods

### 1ï¸âƒ£ Full Fine-Tuning (FFT)
- Updates all model parameters
- Higher memory cost
- More expressive adaptation

### 2ï¸âƒ£ LoRA
Implemented via PEFT:
- Injects low-rank matrices into attention layers
- Freezes backbone model
- Trains only a small percentage of parameters
- Reduces GPU memory usage significantly

---

## ğŸ“Š Dataset

File:
data/all-data.csv

Format:
label, text

Processing steps:
- Text cleaning
- Label normalization
- Stratified train/validation split

---

## ğŸ“ Evaluation Metrics

Primary metric:
- Macro F1-score

Additional metrics:
- Accuracy
- Precision
- Recall

Macro F1 is used for:
- Early stopping
- Best model selection

---

## ğŸš€ How to Run

### Using Notebooks (Recommended)

1. Data loading:
   notebook/01_data_loading.ipynb

2. Training:
   notebook/02_training_lora(deberta-v3-base).ipynb

3. Evaluation:
   notebook/03_evaluation.ipynb

---

### Using Docker

docker-compose build
docker-compose up

---

## âš™ï¸ Environment Setup

pip install -r requirements.txt

Key libraries:
- transformers
- peft
- torch
- scikit-learn
- datasets

---

## ğŸ¯ Experimental Focus

Hyperparameters explored:
- Learning rate
- LoRA rank (r)
- LoRA alpha
- LoRA dropout
- Class weights

Sequential progressive tuning strategy applied.

---

## ğŸ‘¤ Author

Patrick Yip  
Master of IT in Business (AI)  
Singapore Management University
